{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.image as img\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.image as img\n",
    "from keras.preprocessing.image import ImageDataGenerator, Iterator, flip_axis\n",
    "from keras.layers.core import Dense, Flatten, Activation, SpatialDropout2D, Lambda, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.objectives import mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 1. Read Data from Driving Log\n",
    "driving_log = pd.read_csv('driving_log.csv', index_col=False)\n",
    "driving_log.columns = ['center_imgpath', 'left_imgpath', 'right_imgpath', 'angle', 'throttle', 'break', 'speed']\n",
    "\n",
    "# 2. Prepare Data for Generator\n",
    "X_train_path, y_train = [], []\n",
    "for index, row in driving_log.iterrows():\n",
    "    # Include center image and steering angle.\n",
    "    X_train_path.append(row['center_imgpath'])\n",
    "    y_train.append(row['angle'])\n",
    "    \n",
    "    \n",
    "    C = row['angle']\n",
    "    L = C + 0.07\n",
    "    R = C - 0.07\n",
    "        \n",
    "    X_train_path.append(row['left_imgpath'].strip())\n",
    "    y_train.append(L)\n",
    "        \n",
    "    X_train_path.append(row['right_imgpath'].strip())\n",
    "    y_train.append(R)\n",
    "    \n",
    "  \n",
    "X_train_path, y_train = np.array(X_train_path), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_imgs(img_paths):\n",
    "    \"\"\"\n",
    "    read images from file path.\n",
    "    \"\"\"        \n",
    "    imgs = np.empty([len(img_paths), 160, 320, 3])\n",
    "\n",
    "    for i, path in enumerate(img_paths):\n",
    "        imgs[i] = imread(path)\n",
    "\n",
    "    return imgs\n",
    "\n",
    "def resize(X):\n",
    "    import tensorflow\n",
    "    return tensorflow.image.resize_images(X, (40, 160))\n",
    "\n",
    "def gen_batches(imgs, angles, batch_size):\n",
    "    \"\"\"\n",
    "    Generates random batches of the input data.\n",
    "    :imgs: The input image file paths\n",
    "    :angles: The steering angles associated with each image.\n",
    "    :batch_size: The size of each minibatch.\n",
    "    :yeilds A tuple (images, angles), where both images and angles have batch_size elements.\n",
    "    \"\"\"\n",
    "    num_imgs = len(imgs)\n",
    "\n",
    "    while True:\n",
    "        indices = np.random.choice(num_imgs, batch_size)\n",
    "        batch_imgs_raw, angles_raw = read_imgs(imgs[indices]), angles[indices].astype(float)\n",
    "        yield batch_imgs_raw, angles_raw\n",
    "        \n",
    "def get_model():\n",
    "    \n",
    "    model = Sequential([\n",
    "        # Preprocess\n",
    "        # Resize images to improve performance\n",
    "        # Normalize to keep weight values small with zero mean, improving numerical stability.\n",
    "        Lambda(resize, input_shape=(160, 320, 3)),\n",
    "        BatchNormalization(axis=1),\n",
    "        # Conv 5x5\n",
    "        Convolution2D(24, 5, 5, border_mode='same', activation='elu'),\n",
    "        MaxPooling2D(border_mode='same'),\n",
    "        SpatialDropout2D(0.2),\n",
    "        # Conv 5x5\n",
    "        Convolution2D(36, 5, 5, border_mode='same', activation='elu'),\n",
    "        MaxPooling2D(border_mode='same'),\n",
    "        SpatialDropout2D(0.2),\n",
    "        # Conv 5x5\n",
    "        Convolution2D(48, 5, 5, border_mode='same', activation='elu'),\n",
    "        MaxPooling2D(border_mode='same'),\n",
    "        SpatialDropout2D(0.2),\n",
    "        # Conv 3x3\n",
    "        Convolution2D(64, 3, 3, border_mode='same', activation='elu'),\n",
    "        MaxPooling2D(border_mode='same'),\n",
    "        SpatialDropout2D(0.2),\n",
    "        # Conv 3x3\n",
    "        Convolution2D(64, 3, 3, border_mode='same', activation='elu'),\n",
    "        MaxPooling2D(border_mode='same'),\n",
    "        SpatialDropout2D(0.2),\n",
    "        # Flatten\n",
    "        Flatten(),\n",
    "        # Fully Connected\n",
    "        Dense(100, activation='elu', W_regularizer=l2(1e-6)),\n",
    "        Dense(50, activation='elu', W_regularizer=l2(1e-6)),\n",
    "        Dense(10, activation='elu', W_regularizer=l2(1e-6)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def save_model(model):\n",
    "    with open('model.json', 'w') as outfile:\n",
    "        json.dump(model.to_json(), outfile)\n",
    "    model.save_weights('model.h5')\n",
    "\n",
    "    print ('Model saved!')\n",
    "    \n",
    "    return Truet tensorflow\n",
    "    return tensorflow.image.resize_images(X, (40, 160))\n",
    "\n",
    "def gen_batches(imgs, angles, batch_size):\n",
    "    \"\"\"\n",
    "    Generates random batches of the input data.\n",
    "    :imgs: The input image file paths\n",
    "    :angles: The steering angles associated with each image.\n",
    "    :batch_size: The size of each minibatch.\n",
    "    :yeilds A tuple (images, angles), where both images and angles have batch_size elements.\n",
    "    \"\"\"\n",
    "    num_imgs = len(imgs)\n",
    "\n",
    "    while True:\n",
    "        indices = np.random.choice(num_imgs, batch_size)\n",
    "        batch_imgs_raw, angles_raw = read_imgs(imgs[indices]), angles[indices].astype(float)\n",
    "        yield batch_imgs_raw, angles_raw\n",
    "        \n",
    "def get_model():\n",
    "    \n",
    "    model = Sequential([\n",
    "        # Preprocess\n",
    "        # Resize images to improve performance\n",
    "        # Normalize to keep weight values small with zero mean, improving numerical stability.\n",
    "        Lambda(resize, input_shape=(160, 320, 3)),\n",
    "        BatchNormalization(axis=1),\n",
    "        # Conv 5x5\n",
    "        Convolution2D(24, 5, 5, border_mode='same', activation='elu'),\n",
    "        MaxPooling2D(border_mode='same'),\n",
    "        SpatialDropout2D(0.2),\n",
    "        # Conv 5x5\n",
    "        Convolution2D(36, 5, 5, border_mode='same', activation='elu'),\n",
    "        MaxPooling2D(border_mode='same'),\n",
    "        SpatialDropout2D(0.2),\n",
    "        # Conv 5x5\n",
    "        Convolution2D(48, 5, 5, border_mode='same', activation='elu'),\n",
    "        MaxPooling2D(border_mode='same'),\n",
    "        SpatialDropout2D(0.2),\n",
    "        # Conv 3x3\n",
    "        Convolution2D(64, 3, 3, border_mode='same', activation='elu'),\n",
    "        MaxPooling2D(border_mode='same'),\n",
    "        SpatialDropout2D(0.2),\n",
    "        # Conv 3x3\n",
    "        Convolution2D(64, 3, 3, border_mode='same', activation='elu'),\n",
    "        MaxPooling2D(border_mode='same'),\n",
    "        SpatialDropout2D(0.2),\n",
    "        # Flatten\n",
    "        Flatten(),\n",
    "        # Fully Connected\n",
    "        Dense(100, activation='elu', W_regularizer=l2(1e-6)),\n",
    "        Dense(50, activation='elu', W_regularizer=l2(1e-6)),\n",
    "        Dense(10, activation='elu', W_regularizer=l2(1e-6)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def save_model(model):\n",
    "    with open('model.json', 'w') as outfile:\n",
    "        json.dump(model.to_json(), outfile)\n",
    "    model.save_weights('model.h5')\n",
    "\n",
    "    print ('Model saved!')\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6016/6027 [============================>.] - ETA: 0s - loss: 0.1851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd/lib/python3.5/site-packages/keras/engine/training.py:1528: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6144/6027 [==============================] - 39s - loss: 0.1820 - val_loss: 0.0189\n",
      "Epoch 2/5\n",
      "6144/6027 [==============================] - 35s - loss: 0.0187 - val_loss: 0.0138\n",
      "Epoch 3/5\n",
      "6144/6027 [==============================] - 35s - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 4/5\n",
      "6144/6027 [==============================] - 36s - loss: 0.0150 - val_loss: 0.0132\n",
      "Epoch 5/5\n",
      "6144/6027 [==============================] - 35s - loss: 0.0146 - val_loss: 0.0120\n",
      "Model saved!\n",
      "Training completed in 189.754389s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizer='adam', loss = 'mse')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_path, y_train)\n",
    "\n",
    "nb_val_samples = len(y_val)\n",
    "gen = gen_batches(X_train, y_train, 128)\n",
    "\n",
    "model.fit_generator(gen,\n",
    "    samples_per_epoch=len(y_train),\n",
    "    validation_data=gen_batches(X_val,y_val, 128),\n",
    "    nb_val_samples=nb_val_samples,\n",
    "    nb_epoch=5\n",
    ")\n",
    "\n",
    "# Save Model/Weights\n",
    "save_model(model)\n",
    "\n",
    "end = time.clock()\n",
    "print (\"Training completed in {:2f}s\".format(end - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = X_train_path[0:5]\n",
    "\n",
    "test2 = []\n",
    "for line in test:\n",
    "    test2.append(line.split('IMG',1)[-1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CarND-LeNet-Lab]",
   "language": "python",
   "name": "conda-env-CarND-LeNet-Lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
